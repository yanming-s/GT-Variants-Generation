num_transformer_layers: 5
num_attention_heads: 8
hidden_dim: 128
dropout: 0.0